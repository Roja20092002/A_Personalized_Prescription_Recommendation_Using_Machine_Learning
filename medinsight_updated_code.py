# -*- coding: utf-8 -*-
"""MedInsight_Updated_Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pFAYlCcyx3CgdJpqIveODOFyPFNyFuT0
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd # data preprocessing
import itertools # confusion matrix
import string
import numpy as np
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
import matplotlib.pyplot as plt
# %matplotlib inline
# To show all the rows of pandas dataframe
# pd.set_option('display.max_rows', None)

df = pd.read_csv('/content/drugsComTrain_raw.tsv', sep='\t')

df = df.drop(columns=['Unnamed: 0'])

df.head()

df

import matplotlib.pyplot as plt

# Filter the DataFrame to keep only the specified conditions
df_filtered = df[df['condition'].isin(['Birth Control', 'Diabetes, Type 2', 'High Blood Pressure', 'Depression'])]

# Count the number of reviews for each condition
condition_counts = df_filtered['condition'].value_counts()

# Create the bar plot
plt.figure(figsize=(10, 6))
condition_counts.plot(kind='bar')
plt.title('Number of Reviews per Condition')
plt.xlabel('Condition')
plt.ylabel('Number of Reviews')
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt

# Filter the DataFrame to keep only the specified conditions
df_filtered = df[df['condition'].isin(['Birth Control', 'Diabetes, Type 2', 'High Blood Pressure', 'Depression'])]

# Count the number of reviews for each condition
condition_counts = df_filtered['condition'].value_counts()

# Define a color list for each bar (using the pastel colors from the image)
colors = ['#B3E2CD', '#FDCDAC', '#F4CAE4', '#CBD6EB']  # Adjust colors as needed

# Create the bar plot
plt.figure(figsize=(10, 6))
bars = condition_counts.plot(kind='bar', color=colors)

# Get bar positions and heights
x_positions = bars.patches[0].get_x()  # Assuming all bars have the same width
bar_heights = bars.get_height()

# Highlight peak points with annotations (optional)
# ... (code for highlighting peak points remains the same)

# Customize the plot
plt.title('Number of Reviews per Condition')
plt.xlabel('Condition')
plt.ylabel('Number of Reviews')
plt.xticks(rotation=180)
plt.yticks(rotation=45)
plt.grid(axis='y')  # Add grid lines for better readability
plt.tight_layout()  # Adjust spacing between elements
plt.show()

df.condition.value_counts().head()

df_train = df[(df['condition']=='Birth Control') | (df['condition']=='Depression') | (df['condition']=='High Blood Pressure')|(df['condition']=='Diabetes, Type 2')]

df.shape

df_train.shape

df_train

X = df_train.drop(['drugName','rating','date','usefulCount'],axis=1)

X.condition.value_counts()

X.head()

X

# segregating dataframe for analyzing individual condition
X_birth=X[(X['condition']=='Birth Control')]
X_dep=X[(X['condition']=='Depression')]
X_bp=X[(X['condition']=='High Blood Pressure')]
X_diab=X[(X['condition']=='Diabetes, Type 2')]

print('Birth Control:', X_birth.review.count())
print('Depression:',X_dep.review.count())
print('Blood Pressure:',X_bp.review.count())
print('Diabetes, Type 2:',X_diab.review.count())

from wordcloud import WordCloud
plt.figure(figsize = (20,20)) # Text that is Fake News Headlines
wc = WordCloud(max_words = 500 , width = 1600 , height = 800).generate(" ".join(X_birth.review))
plt.imshow(wc , interpolation = 'bilinear')
plt.title('Word cloud for Birth control',fontsize=14)

plt.figure(figsize = (20,20)) # Text that is Fake News Headlines
wc = WordCloud(max_words = 500 , width = 1600 , height = 800).generate(" ".join(X_dep.review))
plt.imshow(wc , interpolation = 'bilinear')
plt.title('Word cloud for Depression',fontsize=14)

plt.figure(figsize = (20,20)) # Text that is Fake News Headlines
wc = WordCloud(max_words = 500 , width = 1600 , height = 800).generate(" ".join(X_bp.review))
plt.imshow(wc , interpolation = 'bilinear')
plt.title('Word cloud for High Blood Pressure',fontsize=14)

plt.figure(figsize = (20,20)) # Text that is Fake News Headlines
wc = WordCloud(max_words = 500 , width = 1600 , height = 800).generate(" ".join(X_diab.review))
plt.imshow(wc , interpolation = 'bilinear')
plt.title('Word cloud for Diabetes Type 2',fontsize=14)

"""### Data Preprocessing"""

for i, col in enumerate(X.columns):
    X.iloc[:, i] = X.iloc[:, i].str.replace('"', '')

# To set the width of the column to maximum
pd.set_option('max_colwidth', None)

X.head()

import nltk
nltk.download('stopwords')

import nltk
from nltk.corpus import stopwords

# nltk.download('stopwords')  # This can be skipped if already downloaded
stop = stopwords.words('english')

stop

from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer

porter = PorterStemmer()

lemmatizer = WordNetLemmatizer()

print(porter.stem("sportingly"))
print(porter.stem("very"))
print(porter.stem("troubled"))

import nltk
nltk.download('wordnet')

print(lemmatizer.lemmatize("sportingly"))
print(lemmatizer.lemmatize("very"))
print(lemmatizer.lemmatize("troubled"))

from bs4 import BeautifulSoup
import re

def review_to_words(raw_review):
    # 1. Delete HTML
    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()
    # 2. Make a space
    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)
    # 3. lower letters
    words = letters_only.lower().split()
    # 5. Stopwords
    meaningful_words = [w for w in words if not w in stop]
    # 6. lemmitization
    lemmitize_words = [lemmatizer.lemmatize(w) for w in meaningful_words]
    # 7. space join words
    return( ' '.join(lemmitize_words))

X['review_clean'] = X['review'].apply(review_to_words)

X.head()

X_feat=X['review_clean'] # Feature=Cleaned reviews
y=X['condition'] # Target=Condition

X_train, X_test, y_train, y_test = train_test_split(X_feat, y,stratify=y,test_size=0.2, random_state=0)
# y_train= condition labels (target) for training [80% reviews ka conditions]
# y_test= condition labels (target) for testing [20% reviews ka conditions]

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    See full source and example:
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html

    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

# Bag of Words
count_vectorizer = CountVectorizer(stop_words='english')

count_train = count_vectorizer.fit_transform(X_train)

count_test = count_vectorizer.transform(X_test)

count_train.shape # 80% of 42372 total set [Prominent diseases total dataframe] (no. of reviews in training set, cleaned words or vocab)

count_test.shape # 20% of 42372 total set [Prominent diseases total dataframe] (no. of reviews in testing set, cleaned words or vocab)

from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Fit the Multinomial Naive Bayes classifier
mnb = MultinomialNB()
mnb.fit(count_train, y_train) # (no. of reviews + bow, actual reviews) in training set

# Make predictions
pred = mnb.predict(count_test)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Fit the Passive Aggressive Classifier
passive = PassiveAggressiveClassifier()
passive.fit(count_train, y_train)

# Make predictions
pred = passive.predict(count_test)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Use TF-IDF Vectorizer (Unigrams by default)
tfidf = TfidfVectorizer()  # Unigrams
count_train = tfidf.fit_transform(X_train)  # Transform training data
count_test = tfidf.transform(X_test)  # Transform test data

# Fit the Passive Aggressive Classifier
pac = PassiveAggressiveClassifier()
pac.fit(count_train, y_train)

# Make predictions
pred = pac.predict(count_test)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Use TF-IDF Vectorizer with bigrams
tfidf_bigram = TfidfVectorizer(ngram_range=(2, 2))  # Bigrams (2-word combinations)
count_train_bigram = tfidf_bigram.fit_transform(X_train)  # Transform training data
count_test_bigram = tfidf_bigram.transform(X_test)  # Transform test data

# Fit the Passive Aggressive Classifier
pac = PassiveAggressiveClassifier()
pac.fit(count_train_bigram, y_train)

# Make predictions
pred = pac.predict(count_test_bigram)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Use TF-IDF Vectorizer with trigrams
tfidf_trigram = TfidfVectorizer(ngram_range=(3, 3))  # Trigrams (3-word combinations)
count_train_trigram = tfidf_trigram.fit_transform(X_train)  # Transform training data
count_test_trigram = tfidf_trigram.transform(X_test)  # Transform test data

# Fit the Passive Aggressive Classifier
pac = PassiveAggressiveClassifier()
pac.fit(count_train_trigram, y_train)

# Make predictions
pred = pac.predict(count_test_trigram)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Fit the Random Forest Classifier
rf = RandomForestClassifier()
rf.fit(count_train, y_train)

# Make predictions
pred = rf.predict(count_test)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

# from sklearn.svm import SVC
# from sklearn import metrics
# from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
# import matplotlib.pyplot as plt

# # Fit the SVM Classifier
# svm = SVC()
# svm.fit(count_train, y_train)

# # Make predictions
# pred = svm.predict(count_test)

# # Calculate accuracy
# score = metrics.accuracy_score(y_test, pred)
# print("Accuracy:   %0.3f" % score)

# # Calculate precision, recall, and F1-score
# precision = precision_score(y_test, pred, average='weighted') * 100
# recall = recall_score(y_test, pred, average='weighted') * 100
# f1 = f1_score(y_test, pred, average='weighted') * 100

# # Print precision, recall, and F1-score
# print(f"Precision:   {precision:.2f}%")
# print(f"Recall:      {recall:.2f}%")
# print(f"F1-score:    {f1:.2f}%")

# # Create confusion matrix
# cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# # Plot confusion matrix with adjusted figure size
# plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
# disp.plot(cmap=plt.cm.Blues)
# plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
# plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
# plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Fit the Logistic Regression Classifier
logreg = LogisticRegression(max_iter=1000)
logreg.fit(count_train, y_train)

# Make predictions
pred = logreg.predict(count_test)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

from sklearn.ensemble import ExtraTreesClassifier
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Fit the Extra Trees Classifier
etc = ExtraTreesClassifier()
etc.fit(count_train, y_train)

# Make predictions
pred = etc.predict(count_test)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

from sklearn.svm import SVC
from sklearn import metrics
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Fit the SVM Classifier
svm = SVC()
svm.fit(count_train, y_train)

# Make predictions
pred = svm.predict(count_test)

# Calculate accuracy
score = metrics.accuracy_score(y_test, pred)
print("Accuracy:   %0.3f" % score)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, pred, average='weighted') * 100
recall = recall_score(y_test, pred, average='weighted') * 100
f1 = f1_score(y_test, pred, average='weighted') * 100

# Print precision, recall, and F1-score
print(f"Precision:   {precision:.2f}%")
print(f"Recall:      {recall:.2f}%")
print(f"F1-score:    {f1:.2f}%")

# Create confusion matrix
cm = confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])

# Plot confusion matrix with adjusted figure size
plt.figure(figsize=(10, 6))  # Adjust the figure size as needed
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Birth Control', 'Depression', 'Diabetes, Type 2', 'High Blood Pressure'])
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # Adjust padding
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier

# Define and fit the TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))  # Example with n-grams (unigrams, bigrams, trigrams)
tfidf_train = tfidf_vectorizer.fit_transform(X_train)
tfidf_test = tfidf_vectorizer.transform(X_test)

# Train Passive Aggressive Classifier
pass_tf = PassiveAggressiveClassifier()
pass_tf.fit(tfidf_train, y_train)

# Most Important Features function
def most_informative_feature_for_class(vectorizer, classifier, classlabel, n=10):
    labelid = list(classifier.classes_).index(classlabel)
    feature_names = vectorizer.get_feature_names_out()  # Updated method for feature names
    topn = sorted(zip(classifier.coef_[labelid], feature_names))[-n:]

    for coef, feat in topn:
        print(f"{classlabel}: {feat}, Coefficient: {coef:.4f}")

# Call the function with 'Birth Control' class
most_informative_feature_for_class(tfidf_vectorizer, pass_tf, 'Birth Control')

most_informative_feature_for_class(tfidf_vectorizer, pass_tf, 'Depression')

most_informative_feature_for_class(tfidf_vectorizer, pass_tf, 'High Blood Pressure')

most_informative_feature_for_class(tfidf_vectorizer, pass_tf, 'Diabetes, Type 2')

## Function for Extracting Top drugs

def top_drugs_extractor(condition):
    df_top = df[(df['rating']>=9)&(df['usefulCount']>=100)].sort_values(by = ['rating', 'usefulCount'], ascending = [False, False])
    drug_lst = df_top[df_top['condition']==condition]['drugName'].head(3).tolist()
    return drug_lst

def predict_text(lst_text):
    # Create a DataFrame for the input text
    df_test = pd.DataFrame(lst_text, columns=['test_sent'])

    # Apply text preprocessing using the 'review_to_words' function
    df_test["test_sent"] = df_test["test_sent"].apply(review_to_words)

    # Ensure tfidf_vectorizer3 is already fitted on your training data
    # Transform the input text using the existing TF-IDF vectorizer
    tfidf_bigram = tfidf_vectorizer.transform(df_test["test_sent"])  # Use the processed text column

    # Predict the labels using the trained PassiveAggressiveClassifier (or other classifier)
    prediction = pass_tf.predict(tfidf_bigram)

    # Add predictions to the DataFrame
    df_test['prediction'] = prediction

    return df_test

sentences = [
  "I have only been on Tekturna for 9 days. The effect was immediate. I am also on a calcium channel blocker (Tiazac) and hydrochlorothiazide. I was put on Tekturna because of palpitations experienced with Diovan (ugly drug in my opinion, same company produces both however). The palpitations were pretty bad on Diovan, 24 hour monitor by EKG etc. After a few days of substituting Tekturna for Diovan, there are no more palpitations.",
    "This is the third med I&#039;ve tried for anxiety and mild depression. Been on it for a week and I hate it so much. I am so dizzy, I have major diarrhea and feel worse than I started. Contacting my doc in the am and changing asap.",
    "I just got diagnosed with type 2. My doctor prescribed Invokana and metformin from the beginning. My sugars went down to normal by the second week. I am losing so much weight. No side effects yet. Miracle medicine for me", "I switched to Portia 12 days ago when I started spotting from another birth control (Alesse). I just wanted to say I started taking Portia on Tuesday and have been crying for consecutive days from Friday to Tuesday out of no where. I have also found it very hard to get studying and made me a much lazier person. I will be discontinuing this birth control today because my mood swings were affecting me too much.", ""

  ]

from sklearn.feature_extraction.text import TfidfVectorizer
import textwrap  # Import the textwrap module

# Assuming you have some training data
tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))  # Example with n-grams (unigrams, bigrams, trigrams)
tfidf_train = tfidf_vectorizer.fit_transform(X_train)

# Now transform the sentences
tfidf_trigram = tfidf_vectorizer.transform(sentences)

# Make predictions
predictions = pass_tf.predict(tfidf_trigram)

# Set the maximum width for wrapped text
max_width = 80  # Adjust as needed

# Process predictions
for text, label in zip(sentences, predictions):
    if label == "High Blood Pressure":
        target = "High Blood Pressure"
        top_drugs = top_drugs_extractor(label)
    elif label == "Depression":
        target = "Depression"
        top_drugs = top_drugs_extractor(label)
    elif label == "Diabetes, Type 2":
        target = "Diabetes, Type 2"
        top_drugs = top_drugs_extractor(label)
    else:
        target = "Birth Control"
        top_drugs = top_drugs_extractor(label)

    # Print wrapped text
    print("text:", textwrap.fill(text, max_width), target)  # Wrap text output
    print()
    print("Condition:", target)
    print()
    print("Top 3 Suggested Drugs:")
    print()
    print(textwrap.fill(top_drugs[0], max_width))
    print(textwrap.fill(top_drugs[1], max_width))
    print(textwrap.fill(top_drugs[2], max_width))
    print()  # Add a newline for better readability



filtered_reviews = X[X['review'].str.contains('birth control', case=False)]

filtered_reviews